{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rPjOk7xbe9A"
      },
      "source": [
        "The whold training and testing is on Google Colab. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6vkptkhj7Lh",
        "outputId": "b1b4a528-f749-41d7-a66d-f006f4667afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZf_l_SGkIZb",
        "outputId": "f7959a70-a7c7-4b27-b4e8-3520e7e14ce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lab2_test_data.h5',\n",
              " 'lab2_train_data.h5',\n",
              " 'vgg16_bn-6c64b313.pth',\n",
              " 'weights',\n",
              " 'main_segnet_v1.ipynb',\n",
              " 'results']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = \"/content/drive/My Drive/segnet/\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9XFtbHkazqh",
        "outputId": "cf15f73c-8ce1-498a-e65d-b8da7838a3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/segnet\n"
          ]
        }
      ],
      "source": [
        "import  os\n",
        "print (os.getcwd()) # get current working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHM-6uBjX3k"
      },
      "source": [
        "# 0. parameters\n",
        "## 0.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQSaRIwojX3l"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "import torch\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "108R3g06jX3n"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "n_epochs = 10 # training epochs\n",
        "class_num = 34\n",
        "batch_size = 20 # should be no less than 5\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 5e-4\n",
        "log_interval = 10\n",
        "random_seed = 42\n",
        "val_percent = 0.1 # training set : validation set = 9:1\n",
        "torch.manual_seed(random_seed)\n",
        "bn_momentum = 0.1  # momentum for batch normalization\n",
        "\n",
        "cate_weight = [1/34]*34 # weight for each class\n",
        "dir_pre_train_weights = \"vgg16_bn-6c64b313.pth\" # pre_train weights downloaded from https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\n",
        "dir_weights = \"./weights\"\n",
        "dir_checkpoint = './checkpoints'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNogkTLqjX3o"
      },
      "source": [
        "# 1.Implement a data loader class to handle the downloaded data. (5 points)\n",
        "For more information on the dataset please refer to: CityScapes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNDPQBRsSOBH"
      },
      "outputs": [],
      "source": [
        "color_codes = h5py.File(\"lab2_test_data.h5\", 'r')['color_codes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDrWorCujX3o"
      },
      "outputs": [],
      "source": [
        "# 'rgb' stores the raw images, while 'seg' stores segmentation maps\n",
        "class DataFromH5File(data.Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        h5File = h5py.File(filepath, 'r')\n",
        "        # self.color_codes = h5File['color_codes']\n",
        "        self.rgb = h5File['rgb']\n",
        "        self.seg = h5File['seg']\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        label = torch.from_numpy(self.seg[idx]).float()\n",
        "        data = torch.from_numpy(self.rgb[idx]).float()\n",
        "        data = data/255.0 # normalization\n",
        "        data = data.permute(2,0,1) # change the image channels into （channel, width, height）\n",
        "        return data, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert self.rgb.shape[0] == self.seg.shape[0], \"Wrong data length\" # robustness\n",
        "        return self.rgb.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUoAgwEPjX3p"
      },
      "outputs": [],
      "source": [
        "# load training data from lab2_train_data.h5\n",
        "dataset = DataFromH5File(\"lab2_train_data.h5\")\n",
        "n_val = int(len(dataset) * val_percent)\n",
        "n_train = len(dataset) - n_val\n",
        "\n",
        "# split train & val\n",
        "train, val = data.random_split(dataset, [n_train, n_val])\n",
        "train_loader = data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last = True)\n",
        "val_loader = data.DataLoader(dataset=val, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last = True) # drop_last=True\n",
        "\n",
        "# load testing data from lab2_test_data.h5\n",
        "testset = DataFromH5File(\"lab2_test_data.h5\")\n",
        "test_loader = data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvzb0C0ojX3p",
        "outputId": "f9b99dc4-90bb-440b-b916-3ffbdafc816b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(1.)\n",
            "tensor(1.) tensor(33.)\n",
            "0\n",
            "133 14 25\n"
          ]
        }
      ],
      "source": [
        "# test the data loader\n",
        "for step, (x, y) in enumerate(train_loader):\n",
        "    print(x.min(),x.max())\n",
        "    print(y.min(),y.max())\n",
        "    print(step)\n",
        "    break\n",
        "\n",
        "print(len(train_loader), len(val_loader), len(test_loader)) # 669 74 125 when batch_size==4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVPNv7I1jX3q"
      },
      "source": [
        "# 2. Define the model. Provide a schematic of your architecture depicting its overall structure and the relevant parameters. (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6whmGCmRdQmc"
      },
      "source": [
        "## 2.1 Define the model.\n",
        "SegNet proposed by Badrinarayanan et al.   \n",
        "Paper link:https://arxiv.org/pdf/1511.00561.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td8VznZKaq-1"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.enco1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.enco2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.enco3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.enco4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.enco5 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        id = []\n",
        "\n",
        "        x = self.enco1(x)\n",
        "        x, id1 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)  # 保留最大值的位置\n",
        "        id.append(id1)\n",
        "        x = self.enco2(x)\n",
        "        x, id2 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        id.append(id2)\n",
        "        x = self.enco3(x)\n",
        "        x, id3 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        id.append(id3)\n",
        "        x = self.enco4(x)\n",
        "        x, id4 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        id.append(id4)\n",
        "        x = self.enco5(x)\n",
        "        x, id5 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        id.append(id5)\n",
        "\n",
        "        return x, id\n",
        "\n",
        "\n",
        "# encoder + decoder\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels):\n",
        "        super(SegNet, self).__init__()\n",
        "\n",
        "        self.weights_new = self.state_dict()\n",
        "        self.encoder = Encoder(input_channels)\n",
        "\n",
        "        self.deco1 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deco2 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deco3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deco4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=bn_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.deco5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=bn_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, output_channels, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, id = self.encoder(x)\n",
        "\n",
        "        x = F.max_unpool2d(x, id[4], kernel_size=2, stride=2)\n",
        "        x = self.deco1(x)\n",
        "        x = F.max_unpool2d(x, id[3], kernel_size=2, stride=2)\n",
        "        x = self.deco2(x)\n",
        "        x = F.max_unpool2d(x, id[2], kernel_size=2, stride=2)\n",
        "        x = self.deco3(x)\n",
        "        x = F.max_unpool2d(x, id[1], kernel_size=2, stride=2)\n",
        "        x = self.deco4(x)\n",
        "        x = F.max_unpool2d(x, id[0], kernel_size=2, stride=2)\n",
        "        x = self.deco5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # delete weights of three fc layers\n",
        "    def load_weights(self, weights_path):\n",
        "        weights = torch.load(weights_path)\n",
        "        del weights[\"classifier.0.weight\"]\n",
        "        del weights[\"classifier.0.bias\"]\n",
        "        del weights[\"classifier.3.weight\"]\n",
        "        del weights[\"classifier.3.bias\"]\n",
        "        del weights[\"classifier.6.weight\"]\n",
        "        del weights[\"classifier.6.bias\"]\n",
        "\n",
        "        names = []\n",
        "        for key, value in self.encoder.state_dict().items():\n",
        "            if \"num_batches_tracked\" in key:\n",
        "                continue\n",
        "            names.append(key)\n",
        "\n",
        "        for name, dict in zip(names, weights.items()):\n",
        "            self.weights_new[name] = dict[1]\n",
        "\n",
        "        self.encoder.load_state_dict(self.weights_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u558tpeDfnAd"
      },
      "source": [
        "## 2.2 Provide a schematic of your architecture depicting its overall structure and the relevant parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1qAOBBmgF2L"
      },
      "source": [
        "![1644863391(1).png](https://s2.loli.net/2022/02/15/bLZQdkYe94qUtMI.png)\n",
        "$$\\rm Figure 1.model\\; architecture$$ \n",
        "$$\\rm As\\; shown\\; above,\\; the\\; encoder\\; of\\; SegNet\\; is\\; the\\; same\\;as\\; VGG16\\; without\\; fc\\; layers.$$   \n",
        "$$\\rm Note:\\; Badrinarayanan,\\; Vijay\\; et\\; al.\\; “SegNet:\\; A\\; Deep\\; Convolutional\\; Encoder-Decoder\\; Architecture\\; for\\; Image\\; Segmentation.” IEEE\\; transactions\\; on\\; pattern\\; analysis\\; and\\; machine\\; intelligence\\; vol.\\; 39,12\\; (2017):\\; 2481-2495.\\; doi:10.1109/TPAMI.2016.2644615$$   \n",
        "   \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKVzHiXfaq-2"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ewA8Mf4drRM"
      },
      "outputs": [],
      "source": [
        "# use this version to avoid bugs\n",
        "# !pip install torch-summary==1.4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfDZiuiWaq-3",
        "outputId": "4a9fd8c1-81ad-4c54-e35d-ea35ff0ae2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 34, 128, 256])\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "├─Encoder: 1-1                           --\n",
            "|    └─Sequential: 2-1                   --\n",
            "|    |    └─Conv2d: 3-1                  1,792\n",
            "|    |    └─BatchNorm2d: 3-2             128\n",
            "|    |    └─ReLU: 3-3                    --\n",
            "|    |    └─Conv2d: 3-4                  36,928\n",
            "|    |    └─BatchNorm2d: 3-5             128\n",
            "|    |    └─ReLU: 3-6                    --\n",
            "|    └─Sequential: 2-2                   --\n",
            "|    |    └─Conv2d: 3-7                  73,856\n",
            "|    |    └─BatchNorm2d: 3-8             256\n",
            "|    |    └─ReLU: 3-9                    --\n",
            "|    |    └─Conv2d: 3-10                 147,584\n",
            "|    |    └─BatchNorm2d: 3-11            256\n",
            "|    |    └─ReLU: 3-12                   --\n",
            "|    └─Sequential: 2-3                   --\n",
            "|    |    └─Conv2d: 3-13                 295,168\n",
            "|    |    └─BatchNorm2d: 3-14            512\n",
            "|    |    └─ReLU: 3-15                   --\n",
            "|    |    └─Conv2d: 3-16                 590,080\n",
            "|    |    └─BatchNorm2d: 3-17            512\n",
            "|    |    └─ReLU: 3-18                   --\n",
            "|    |    └─Conv2d: 3-19                 590,080\n",
            "|    |    └─BatchNorm2d: 3-20            512\n",
            "|    |    └─ReLU: 3-21                   --\n",
            "|    └─Sequential: 2-4                   --\n",
            "|    |    └─Conv2d: 3-22                 1,180,160\n",
            "|    |    └─BatchNorm2d: 3-23            1,024\n",
            "|    |    └─ReLU: 3-24                   --\n",
            "|    |    └─Conv2d: 3-25                 2,359,808\n",
            "|    |    └─BatchNorm2d: 3-26            1,024\n",
            "|    |    └─ReLU: 3-27                   --\n",
            "|    |    └─Conv2d: 3-28                 2,359,808\n",
            "|    |    └─BatchNorm2d: 3-29            1,024\n",
            "|    |    └─ReLU: 3-30                   --\n",
            "|    └─Sequential: 2-5                   --\n",
            "|    |    └─Conv2d: 3-31                 2,359,808\n",
            "|    |    └─BatchNorm2d: 3-32            1,024\n",
            "|    |    └─ReLU: 3-33                   --\n",
            "|    |    └─Conv2d: 3-34                 2,359,808\n",
            "|    |    └─BatchNorm2d: 3-35            1,024\n",
            "|    |    └─ReLU: 3-36                   --\n",
            "|    |    └─Conv2d: 3-37                 2,359,808\n",
            "|    |    └─BatchNorm2d: 3-38            1,024\n",
            "|    |    └─ReLU: 3-39                   --\n",
            "├─Sequential: 1-2                        --\n",
            "|    └─Conv2d: 2-6                       2,359,808\n",
            "|    └─BatchNorm2d: 2-7                  1,024\n",
            "|    └─ReLU: 2-8                         --\n",
            "|    └─Conv2d: 2-9                       2,359,808\n",
            "|    └─BatchNorm2d: 2-10                 1,024\n",
            "|    └─ReLU: 2-11                        --\n",
            "|    └─Conv2d: 2-12                      2,359,808\n",
            "|    └─BatchNorm2d: 2-13                 1,024\n",
            "|    └─ReLU: 2-14                        --\n",
            "├─Sequential: 1-3                        --\n",
            "|    └─Conv2d: 2-15                      2,359,808\n",
            "|    └─BatchNorm2d: 2-16                 1,024\n",
            "|    └─ReLU: 2-17                        --\n",
            "|    └─Conv2d: 2-18                      2,359,808\n",
            "|    └─BatchNorm2d: 2-19                 1,024\n",
            "|    └─ReLU: 2-20                        --\n",
            "|    └─Conv2d: 2-21                      1,179,904\n",
            "|    └─BatchNorm2d: 2-22                 512\n",
            "|    └─ReLU: 2-23                        --\n",
            "├─Sequential: 1-4                        --\n",
            "|    └─Conv2d: 2-24                      590,080\n",
            "|    └─BatchNorm2d: 2-25                 512\n",
            "|    └─ReLU: 2-26                        --\n",
            "|    └─Conv2d: 2-27                      590,080\n",
            "|    └─BatchNorm2d: 2-28                 512\n",
            "|    └─ReLU: 2-29                        --\n",
            "|    └─Conv2d: 2-30                      295,040\n",
            "|    └─BatchNorm2d: 2-31                 256\n",
            "|    └─ReLU: 2-32                        --\n",
            "├─Sequential: 1-5                        --\n",
            "|    └─Conv2d: 2-33                      147,584\n",
            "|    └─BatchNorm2d: 2-34                 256\n",
            "|    └─ReLU: 2-35                        --\n",
            "|    └─Conv2d: 2-36                      73,792\n",
            "|    └─BatchNorm2d: 2-37                 128\n",
            "|    └─ReLU: 2-38                        --\n",
            "├─Sequential: 1-6                        --\n",
            "|    └─Conv2d: 2-39                      36,928\n",
            "|    └─BatchNorm2d: 2-40                 128\n",
            "|    └─ReLU: 2-41                        --\n",
            "|    └─Conv2d: 2-42                      19,618\n",
            "=================================================================\n",
            "Total params: 29,462,626\n",
            "Trainable params: 29,462,626\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "├─Encoder: 1-1                           --\n",
              "|    └─Sequential: 2-1                   --\n",
              "|    |    └─Conv2d: 3-1                  1,792\n",
              "|    |    └─BatchNorm2d: 3-2             128\n",
              "|    |    └─ReLU: 3-3                    --\n",
              "|    |    └─Conv2d: 3-4                  36,928\n",
              "|    |    └─BatchNorm2d: 3-5             128\n",
              "|    |    └─ReLU: 3-6                    --\n",
              "|    └─Sequential: 2-2                   --\n",
              "|    |    └─Conv2d: 3-7                  73,856\n",
              "|    |    └─BatchNorm2d: 3-8             256\n",
              "|    |    └─ReLU: 3-9                    --\n",
              "|    |    └─Conv2d: 3-10                 147,584\n",
              "|    |    └─BatchNorm2d: 3-11            256\n",
              "|    |    └─ReLU: 3-12                   --\n",
              "|    └─Sequential: 2-3                   --\n",
              "|    |    └─Conv2d: 3-13                 295,168\n",
              "|    |    └─BatchNorm2d: 3-14            512\n",
              "|    |    └─ReLU: 3-15                   --\n",
              "|    |    └─Conv2d: 3-16                 590,080\n",
              "|    |    └─BatchNorm2d: 3-17            512\n",
              "|    |    └─ReLU: 3-18                   --\n",
              "|    |    └─Conv2d: 3-19                 590,080\n",
              "|    |    └─BatchNorm2d: 3-20            512\n",
              "|    |    └─ReLU: 3-21                   --\n",
              "|    └─Sequential: 2-4                   --\n",
              "|    |    └─Conv2d: 3-22                 1,180,160\n",
              "|    |    └─BatchNorm2d: 3-23            1,024\n",
              "|    |    └─ReLU: 3-24                   --\n",
              "|    |    └─Conv2d: 3-25                 2,359,808\n",
              "|    |    └─BatchNorm2d: 3-26            1,024\n",
              "|    |    └─ReLU: 3-27                   --\n",
              "|    |    └─Conv2d: 3-28                 2,359,808\n",
              "|    |    └─BatchNorm2d: 3-29            1,024\n",
              "|    |    └─ReLU: 3-30                   --\n",
              "|    └─Sequential: 2-5                   --\n",
              "|    |    └─Conv2d: 3-31                 2,359,808\n",
              "|    |    └─BatchNorm2d: 3-32            1,024\n",
              "|    |    └─ReLU: 3-33                   --\n",
              "|    |    └─Conv2d: 3-34                 2,359,808\n",
              "|    |    └─BatchNorm2d: 3-35            1,024\n",
              "|    |    └─ReLU: 3-36                   --\n",
              "|    |    └─Conv2d: 3-37                 2,359,808\n",
              "|    |    └─BatchNorm2d: 3-38            1,024\n",
              "|    |    └─ReLU: 3-39                   --\n",
              "├─Sequential: 1-2                        --\n",
              "|    └─Conv2d: 2-6                       2,359,808\n",
              "|    └─BatchNorm2d: 2-7                  1,024\n",
              "|    └─ReLU: 2-8                         --\n",
              "|    └─Conv2d: 2-9                       2,359,808\n",
              "|    └─BatchNorm2d: 2-10                 1,024\n",
              "|    └─ReLU: 2-11                        --\n",
              "|    └─Conv2d: 2-12                      2,359,808\n",
              "|    └─BatchNorm2d: 2-13                 1,024\n",
              "|    └─ReLU: 2-14                        --\n",
              "├─Sequential: 1-3                        --\n",
              "|    └─Conv2d: 2-15                      2,359,808\n",
              "|    └─BatchNorm2d: 2-16                 1,024\n",
              "|    └─ReLU: 2-17                        --\n",
              "|    └─Conv2d: 2-18                      2,359,808\n",
              "|    └─BatchNorm2d: 2-19                 1,024\n",
              "|    └─ReLU: 2-20                        --\n",
              "|    └─Conv2d: 2-21                      1,179,904\n",
              "|    └─BatchNorm2d: 2-22                 512\n",
              "|    └─ReLU: 2-23                        --\n",
              "├─Sequential: 1-4                        --\n",
              "|    └─Conv2d: 2-24                      590,080\n",
              "|    └─BatchNorm2d: 2-25                 512\n",
              "|    └─ReLU: 2-26                        --\n",
              "|    └─Conv2d: 2-27                      590,080\n",
              "|    └─BatchNorm2d: 2-28                 512\n",
              "|    └─ReLU: 2-29                        --\n",
              "|    └─Conv2d: 2-30                      295,040\n",
              "|    └─BatchNorm2d: 2-31                 256\n",
              "|    └─ReLU: 2-32                        --\n",
              "├─Sequential: 1-5                        --\n",
              "|    └─Conv2d: 2-33                      147,584\n",
              "|    └─BatchNorm2d: 2-34                 256\n",
              "|    └─ReLU: 2-35                        --\n",
              "|    └─Conv2d: 2-36                      73,792\n",
              "|    └─BatchNorm2d: 2-37                 128\n",
              "|    └─ReLU: 2-38                        --\n",
              "├─Sequential: 1-6                        --\n",
              "|    └─Conv2d: 2-39                      36,928\n",
              "|    └─BatchNorm2d: 2-40                 128\n",
              "|    └─ReLU: 2-41                        --\n",
              "|    └─Conv2d: 2-42                      19,618\n",
              "=================================================================\n",
              "Total params: 29,462,626\n",
              "Trainable params: 29,462,626\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SegNet(input_channels=3, output_channels=class_num) # RGB images so the input_channels=3\n",
        "model = model.to(device)\n",
        "x = torch.ones([batch_size, 3, 128, 256]) # input shape\n",
        "x = x.to(device)\n",
        "y = model(x)\n",
        "print(y.shape) # output shape\n",
        "summary(model, input_size=(3, 128, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQgQoaujX3s"
      },
      "source": [
        "# 3. Define the loss function and optimizer. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo-o330bjX3s"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL9dJHSyjX3t"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "# cross entropy loss\n",
        "# To cope with the sample imbalance between different categories, we assign different weights to them.\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array(cate_weight)).float()).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXUulvFDjX3t"
      },
      "source": [
        "# 4. Train the network. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyWKrRJEjX3u"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSvq6hbierWu"
      },
      "outputs": [],
      "source": [
        "model.load_weights(dir_pre_train_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sKZjx4o3ied"
      },
      "source": [
        "The segmentation challenge is evaluated using the mean Intersection over Union (mIoU) metric.         \n",
        "Let $n$ denotes the number of classes, then \n",
        "$$\n",
        "mIoU = \\frac{TP}{TP + FP + FN}\n",
        "=\\frac{1}{n}\\sum_{i = 1}^{n}\\frac{p_{ii}}{\\sum_{j=1}^{n}p_{ij}+\\sum_{j=1}^{n}p_{ji}+p_{ii}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLNZINSW3L20"
      },
      "outputs": [],
      "source": [
        "def mIoU(pred, target):\n",
        "  mini = 1\n",
        "  intersection = pred * (pred == target)\n",
        "\n",
        "  # histogram\n",
        "  area_inter, _ = np.histogram(intersection, bins=2, range=(mini, class_num))\n",
        "  area_pred, _ = np.histogram(pred, bins=2, range=(mini, class_num))\n",
        "  area_target, _ = np.histogram(target, bins=2, range=(mini, class_num))\n",
        "  area_union = area_pred + area_target - area_inter\n",
        "\n",
        "  # Intersection area should be smaller than Union area \n",
        "  assert (area_inter <= area_union).all(), \"Intersection area should be smaller than Union area\"\n",
        "\n",
        "  rate = round(max(area_inter) / max(area_union), 4)\n",
        "  return rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsOg2c9JshYZ"
      },
      "outputs": [],
      "source": [
        "def validate(epoch):\n",
        "  val_pbar = tqdm(val_loader)\n",
        "  for batch_idx, (data, target) in enumerate(val_pbar):\n",
        "    output = model(data.to(device)).to('cpu') # np.histogram requires cpu type tensor\n",
        "    target = target.squeeze().long()\n",
        "    miou = mIoU(output.argmax(dim=1), target) # data.argmax(dim=1) represents the segmentation results\n",
        "    val_pbar.set_description(f\"Validation | Epoch: {epoch} | mIoU: {miou.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZmMxJ9MjX3u"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    target = target.squeeze().long()\n",
        "    # print('output shape=',output.shape)\n",
        "    # print('target shape=',target.shape)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    pbar.set_description(f\"Epoch: {epoch} | Loss: {loss.item():.4f}\")\n",
        "    if batch_idx % log_interval == 0:\n",
        "        train_losses.append(loss.item())\n",
        "        train_counter.append((batch_idx*batch_size) + ((epoch-1)*len(train_loader.dataset)))\n",
        "        # save the parameters\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/segnet/weights/'+str(epoch)+'_model.pth')\n",
        "        torch.save(optimizer.state_dict(), '/content/drive/My Drive/segnet/weights/'+str(epoch)+'_optimizer.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vezH7Xd9jX3u",
        "outputId": "66dd985d-f272-4722-9c73-927ff5c96cf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Loss: 0.7444: 100%|██████████| 133/133 [04:34<00:00,  2.06s/it]\n",
            "Epoch: 2 | Loss: 0.7677: 100%|██████████| 133/133 [04:30<00:00,  2.04s/it]\n",
            "Epoch: 3 | Loss: 0.5926: 100%|██████████| 133/133 [04:28<00:00,  2.02s/it]\n",
            "Epoch: 4 | Loss: 0.5031: 100%|██████████| 133/133 [04:27<00:00,  2.01s/it]\n",
            "Validation | Epoch: 4 | mIoU: 0.7873: 100%|██████████| 14/14 [00:12<00:00,  1.14it/s]\n",
            "Epoch: 5 | Loss: 0.5980: 100%|██████████| 133/133 [04:28<00:00,  2.02s/it]\n",
            "Epoch: 6 | Loss: 0.5380: 100%|██████████| 133/133 [04:28<00:00,  2.02s/it]\n",
            "Epoch: 7 | Loss: 0.5248:  91%|█████████ | 121/133 [04:03<00:27,  2.33s/it]"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    train(epoch)\n",
        "    # validation\n",
        "    if epoch % 4 == 0 or epoch == n_epochs: # or epoch==1:\n",
        "      validate(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOHqfHvTubHJ"
      },
      "source": [
        "plots of the loss evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "SJEKWRWZuaKN",
        "outputId": "a5d3b376-23b6-470f-a0d7-014b88c444dc"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_counter, train_losses)\n",
        "plt.legend(['Train Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('negative log likelihood loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxJmbMaWjX3u"
      },
      "source": [
        "# 5. Test the resulting network on examples from an independent test set. Implement and present: (40 points)\n",
        "a. Predictions for (μ, aleatoric, epistemic) .            \n",
        "b. Visualizations for (μ, aleatoric, epistemic) on 5 different input examples.         \n",
        "c. Comment briefly on how the model’s performance could be improved.          \n",
        "d. Please save your code and results for submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0iw03VJj_au"
      },
      "source": [
        "## 5.1 Predictions and visualizations for $\\mu$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfWi2BfbJWgQ"
      },
      "outputs": [],
      "source": [
        "# color the img according to the color_codes with elegant coding\n",
        "def color(src):\n",
        "  ret = np.zeros((src.shape[0], src.shape[1], 3))\n",
        "  for i in range(class_num):\n",
        "    ret[src==i] = color_codes[i]\n",
        "  return ret\n",
        "\n",
        "# visualize the segmentation results of 5 random test samples\n",
        "def visualize():\n",
        "  rand_idx = random.randint(0,len(test_loader)-1)\n",
        "  \n",
        "  for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    if batch_idx == rand_idx:\n",
        "      data = data.to(device)\n",
        "      output = model(data).to('cpu').argmax(dim=1)\n",
        "      data = data.to('cpu').permute(0,2,3,1)\n",
        "      target = target.squeeze().to('cpu')\n",
        "\n",
        "      for i in range(5):\n",
        "        f, ax = plt.subplots(1, 3, figsize=(10,5)) \n",
        "        ax[0].set_title('Input') #set titles for each parts\n",
        "        ax[0].imshow(data[i])\n",
        "        ax[1].set_title('Output') \n",
        "        ax[1].imshow(color(output[i])/255.0)\n",
        "        ax[2].set_title('GT') \n",
        "        ax[2].imshow(color(target[i])/255.0)\n",
        "        plt.show()\n",
        "\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk3WSM4HHmao"
      },
      "outputs": [],
      "source": [
        "visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekYvWlnMkTM5"
      },
      "source": [
        "## 5.2 Predictions and visualizations for aleatoric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvpsgH3ikhuQ"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHICMXhrkTY9"
      },
      "source": [
        "## 5.3 Predictions and visualizations for epistemic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJzvmm0yjX3v"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUqww_9ckoA8"
      },
      "source": [
        "## 5.4 Comment briefly on how the model’s performance could be improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-KqtoaYkuKt"
      },
      "source": [
        "At the begining, our team used UNet to do the segmentation. However, i tooks nearly 1.5h to train one epoch, which was unaffordable. After searching information about lightweight models, we select SegNet, which enables us to train one epoch **within minutes**.  \n",
        "**The advantage of SegNet is that it don't need to save the feature maps of the entire encoder part, but only the pooling index, which greatly saves memory. Additionaly, it does not need to deconvolute or learn during the upsampling phase.**\n",
        "         \n",
        "Here's some strategies to improve the model's performance:  \n",
        "- Since time is limited, we haven't assign different weight to each class. Considering the imbalaced data distribution, **changing the value of cate_weight**  will help.\n",
        "- Increase **batch size**(using more GPUs). During training, the loss function **fluctuated** severely due to such a small batch size.\n",
        "- Try a couple of activate functions.\n",
        "- Fine-tune parameters in session 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7cmDgG4jX3v"
      },
      "source": [
        "# References\n",
        "[1] https://blog.csdn.net/shwan_ma/article/details/100012808         \n",
        "[2] https://blog.csdn.net/oYeZhou/article/details/112270908      \n",
        "[3] https://blog.csdn.net/qq_32939413/article/details/112117734   \n",
        "[4] Badrinarayanan, Vijay et al. “SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation.” IEEE transactions on pattern analysis and machine intelligence vol. 39,12 (2017): 2481-2495. doi:10.1109/TPAMI.2016.2644615"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "main_segnet_v1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ff5d10bd81a245e546018f81c2d716fad9aa95218d6570327b343e32b2155b52"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('base2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
